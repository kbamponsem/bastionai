<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>bastionai.utils API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>bastionai.utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import io
from typing import Any, Callable, Iterable, Iterator, List, Tuple, TypeVar

import torch
from torch import Tensor
from torch.nn import Module
from torch.nn.parameter import Parameter
from torch.utils.data import Dataset

from pb.remote_torch_pb2 import Chunk

T = TypeVar(&#39;T&#39;)
U = TypeVar(&#39;U&#39;)
SIZE_LEN = 8


def parametrized_modules(module: Module) -&gt; Iterable[Module]:
    &#34;&#34;&#34;
    Recursively iterates over all submodules, returning those that
    have parameters (as opposed to &#34;wrapper modules&#34; that just organize modules).
    &#34;&#34;&#34;
    yield from (
        (m_name, m)  # type: ignore
        for (m_name, m) in module.named_modules()
        if any(p is not None for p in m.parameters(recurse=False))
    )


def trainable_modules(module: Module) -&gt; Iterable[Tuple[str, Module]]:
    &#34;&#34;&#34;
    Recursively iterates over all submodules, returning those that
    have parameters and are trainable (ie they want a grad).
    &#34;&#34;&#34;
    yield from (
        (m_name, m)
        for (m_name, m) in parametrized_modules(module)  # type: ignore
        if any(p.requires_grad for p in m.parameters(recurse=False))
    )


def trainable_parameters(module: Module) -&gt; Iterable[Tuple[str, Parameter]]:
    &#34;&#34;&#34;
    Recursively iterates over all parameters, returning those that
    are trainable (ie they want a grad).
    &#34;&#34;&#34;
    yield from (
        (p_name, p) for (p_name, p) in module.named_parameters() if p.requires_grad
    )


class DataWrapper(Module):
    def __init__(self, samples: torch.Tensor, labels: torch.Tensor) -&gt; None:
        super().__init__()
        self.samples = Parameter(samples)
        self.labels = Parameter(labels)


class ArtifactDataset:
    def __init__(self, chunks: Iterator[Chunk]) -&gt; None:
        wrapper = list(unstream_artifacts(
            (chunk.data for chunk in chunks),
            deserialization_fn=torch.jit.load
        ))[0]  # type: ignore
        self.samples = None
        self.labels = None
        for name, param in wrapper.named_parameters():
            if name == &#34;samples&#34;:
                self.samples = param
            elif name == &#34;labels&#34;:
                self.labels = param
            else:
                raise Exception(f&#34;Unknown field {name} in data wrapper.&#34;)
        if self.samples is None:
            raise Exception(f&#34;Data wrapper must contain a samples field.&#34;)

    def __len__(self) -&gt; int:
        return len(self.samples)

    def __getitem__(self, index: int) -&gt; Any:
        return (self.samples[index], self.labels[index])


# def chunk_bounds(size: int, chunk_size: int) -&gt; Iterator[Tuple[int, int]]:
#     start = 0
#     while start &lt; size:
#         yield (start, min(start + chunk_size, size))
#         start += chunk_size


def chunks(it: Iterator[T], chunk_size: int, cat_fn: Callable[[List[T]], U] = lambda x: x) -&gt; Iterator[U]:
    chunk = []
    for x in it:
        if len(chunk) == chunk_size:
            yield chunk
            chunk = [x]
        else:
            chunk.append(x)
    if len(chunk) &gt; 0:
        yield cat_fn(chunk)


def tensor_to_bytes(tensor: Tensor) -&gt; bytes:
    buff = io.BytesIO()
    torch.save(tensor, buff)
    buff.seek(0)
    return buff.read()


def bytes_to_tensor(bs: bytes) -&gt; Tensor:
    buff = io.BytesIO()
    buff.write(bs)
    buff.seek(0)
    tensor = torch.load(buff)
    return tensor


def serialize_batch(data: Tuple[torch.Tensor, torch.Tensor], buff):
    torch.jit.save(torch.jit.script(DataWrapper(*data)), buff)


def stream_artifacts(artifacts: Iterator[T], chunk_size: int, serialization_fn: Callable[[T, io.BytesIO], None] = torch.save) -&gt; Iterator[bytes]:
    eoi = False
    buff = io.BytesIO()
    while not eoi:
        while buff.tell() &lt; chunk_size:
            try:
                artifact = artifacts.__next__()
                header = buff.tell()
                buff.write(b&#34;\xde\xad\xbe\xef\xde\xad\xbe\xef&#34;)
                serialization_fn(artifact, buff)
                end = buff.tell()
                buff.seek(header)
                buff_len = (end - header - SIZE_LEN).to_bytes(SIZE_LEN,
                                                              byteorder=&#34;little&#34;)
                buff.write(buff_len)
                buff.seek(end)
            except StopIteration:
                eoi = True
                break
        position = buff.tell()
        buff.seek(0)
        if eoi:
            yield buff.read(position)
        else:
            yield buff.read(chunk_size)
            tail = buff.read(position - chunk_size)
            buff.seek(0)
            buff.write(tail)


def unstream_artifacts(stream: Iterator[bytes], deserialization_fn: Callable[[io.BytesIO], T] = torch.load) -&gt; Iterator[T]:
    buff = io.BytesIO()
    init_chunk = stream.__next__()
    size = int.from_bytes(init_chunk[:8], &#34;little&#34;)
    buff.write(init_chunk[8:])
    eoi = False

    while not eoi:
        while buff.tell() &lt; size + 4:
            try:
                buff.write(stream.__next__())
            except StopIteration:
                buff.seek(0)
                yield deserialization_fn(buff)
                eoi = True
                break

        if not eoi:
            end = buff.tell()
            buff.seek(size)
            header = buff.read(SIZE_LEN)
            size = int.from_bytes(header, &#34;little&#34;)
            tail = buff.read(end - size - SIZE_LEN)
            buff.seek(0)
            yield deserialization_fn(buff)
            buff.seek(0)
            buff.write(tail)


def data_chunks_generator(stream: Iterator[bytes], description: str, secret: bytes) -&gt; Iterator[Chunk]:
    first = True
    for x in stream:
        if first:
            first = False
            yield Chunk(data=x, description=description, secret=secret)
        else:
            yield Chunk(data=x, description=&#34;&#34;, secret=bytes())


def make_batch(data: List[Tuple[Tensor, Tensor]]) -&gt; Tuple[Tensor, Tensor]:
    return (torch.cat([x[0] for x in data]), torch.cat([x[1] for x in data]))


def serialize_dataset(dataset: Dataset, description: str, secret: bytes, chunk_size=1000, batch_size=1024) -&gt; Iterator[Chunk]:
    return data_chunks_generator(
        stream_artifacts(
            chunks(iter(dataset), batch_size, cat_fn=make_batch),
            chunk_size,
            serialization_fn=serialize_batch
        ),
        description,
        secret
    )


def serialize_model(model: Module, description: str, secret: bytes, chunk_size=1000) -&gt; Iterator[Chunk]:
    ts = torch.jit.script(model)  # type: ignore
    # type: ignore
    return data_chunks_generator(stream_artifacts(iter([ts]), chunk_size, torch.jit.save), description, secret)


def deserialize_weights_to_model(model: Module, chunks: Iterator[Chunk]) -&gt; None:
    wrapper = list(unstream_artifacts(
        (chunk.data for chunk in chunks),
        deserialization_fn=torch.jit.load
    ))[0]  # type: ignore
    for name, value in wrapper.named_parameters():
        param = model
        parent = None
        segments = name.split(&#34;_&#34;)
        name_buf = []
        for segment in segments:
            name_buf.append(segment)
            name = &#34;_&#34;.join(name_buf)
            if hasattr(param, name):
                parent = param
                param = param.__getattr__(name)
                name_buf = []

        parent.__setattr__(name, torch.nn.Parameter(value))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="bastionai.utils.bytes_to_tensor"><code class="name flex">
<span>def <span class="ident">bytes_to_tensor</span></span>(<span>bs: bytes) ‑> torch.Tensor</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bytes_to_tensor(bs: bytes) -&gt; Tensor:
    buff = io.BytesIO()
    buff.write(bs)
    buff.seek(0)
    tensor = torch.load(buff)
    return tensor</code></pre>
</details>
</dd>
<dt id="bastionai.utils.chunks"><code class="name flex">
<span>def <span class="ident">chunks</span></span>(<span>it: Iterator[~T], chunk_size: int, cat_fn: Callable[[List[~T]], ~U] = &lt;function &lt;lambda&gt;&gt;) ‑> Iterator[~U]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chunks(it: Iterator[T], chunk_size: int, cat_fn: Callable[[List[T]], U] = lambda x: x) -&gt; Iterator[U]:
    chunk = []
    for x in it:
        if len(chunk) == chunk_size:
            yield chunk
            chunk = [x]
        else:
            chunk.append(x)
    if len(chunk) &gt; 0:
        yield cat_fn(chunk)</code></pre>
</details>
</dd>
<dt id="bastionai.utils.data_chunks_generator"><code class="name flex">
<span>def <span class="ident">data_chunks_generator</span></span>(<span>stream: Iterator[bytes], description: str, secret: bytes) ‑> Iterator[remote_torch_pb2.Chunk]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data_chunks_generator(stream: Iterator[bytes], description: str, secret: bytes) -&gt; Iterator[Chunk]:
    first = True
    for x in stream:
        if first:
            first = False
            yield Chunk(data=x, description=description, secret=secret)
        else:
            yield Chunk(data=x, description=&#34;&#34;, secret=bytes())</code></pre>
</details>
</dd>
<dt id="bastionai.utils.deserialize_weights_to_model"><code class="name flex">
<span>def <span class="ident">deserialize_weights_to_model</span></span>(<span>model: torch.nn.modules.module.Module, chunks: Iterator[remote_torch_pb2.Chunk]) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deserialize_weights_to_model(model: Module, chunks: Iterator[Chunk]) -&gt; None:
    wrapper = list(unstream_artifacts(
        (chunk.data for chunk in chunks),
        deserialization_fn=torch.jit.load
    ))[0]  # type: ignore
    for name, value in wrapper.named_parameters():
        param = model
        parent = None
        segments = name.split(&#34;_&#34;)
        name_buf = []
        for segment in segments:
            name_buf.append(segment)
            name = &#34;_&#34;.join(name_buf)
            if hasattr(param, name):
                parent = param
                param = param.__getattr__(name)
                name_buf = []

        parent.__setattr__(name, torch.nn.Parameter(value))</code></pre>
</details>
</dd>
<dt id="bastionai.utils.make_batch"><code class="name flex">
<span>def <span class="ident">make_batch</span></span>(<span>data: List[Tuple[torch.Tensor, torch.Tensor]]) ‑> Tuple[torch.Tensor, torch.Tensor]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_batch(data: List[Tuple[Tensor, Tensor]]) -&gt; Tuple[Tensor, Tensor]:
    return (torch.cat([x[0] for x in data]), torch.cat([x[1] for x in data]))</code></pre>
</details>
</dd>
<dt id="bastionai.utils.parametrized_modules"><code class="name flex">
<span>def <span class="ident">parametrized_modules</span></span>(<span>module: torch.nn.modules.module.Module) ‑> Iterable[torch.nn.modules.module.Module]</span>
</code></dt>
<dd>
<div class="desc"><p>Recursively iterates over all submodules, returning those that
have parameters (as opposed to "wrapper modules" that just organize modules).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parametrized_modules(module: Module) -&gt; Iterable[Module]:
    &#34;&#34;&#34;
    Recursively iterates over all submodules, returning those that
    have parameters (as opposed to &#34;wrapper modules&#34; that just organize modules).
    &#34;&#34;&#34;
    yield from (
        (m_name, m)  # type: ignore
        for (m_name, m) in module.named_modules()
        if any(p is not None for p in m.parameters(recurse=False))
    )</code></pre>
</details>
</dd>
<dt id="bastionai.utils.serialize_batch"><code class="name flex">
<span>def <span class="ident">serialize_batch</span></span>(<span>data: Tuple[torch.Tensor, torch.Tensor], buff)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def serialize_batch(data: Tuple[torch.Tensor, torch.Tensor], buff):
    torch.jit.save(torch.jit.script(DataWrapper(*data)), buff)</code></pre>
</details>
</dd>
<dt id="bastionai.utils.serialize_dataset"><code class="name flex">
<span>def <span class="ident">serialize_dataset</span></span>(<span>dataset: torch.utils.data.dataset.Dataset, description: str, secret: bytes, chunk_size=1000, batch_size=1024) ‑> Iterator[remote_torch_pb2.Chunk]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def serialize_dataset(dataset: Dataset, description: str, secret: bytes, chunk_size=1000, batch_size=1024) -&gt; Iterator[Chunk]:
    return data_chunks_generator(
        stream_artifacts(
            chunks(iter(dataset), batch_size, cat_fn=make_batch),
            chunk_size,
            serialization_fn=serialize_batch
        ),
        description,
        secret
    )</code></pre>
</details>
</dd>
<dt id="bastionai.utils.serialize_model"><code class="name flex">
<span>def <span class="ident">serialize_model</span></span>(<span>model: torch.nn.modules.module.Module, description: str, secret: bytes, chunk_size=1000) ‑> Iterator[remote_torch_pb2.Chunk]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def serialize_model(model: Module, description: str, secret: bytes, chunk_size=1000) -&gt; Iterator[Chunk]:
    ts = torch.jit.script(model)  # type: ignore
    # type: ignore
    return data_chunks_generator(stream_artifacts(iter([ts]), chunk_size, torch.jit.save), description, secret)</code></pre>
</details>
</dd>
<dt id="bastionai.utils.stream_artifacts"><code class="name flex">
<span>def <span class="ident">stream_artifacts</span></span>(<span>artifacts: Iterator[~T], chunk_size: int, serialization_fn: Callable[[~T, _io.BytesIO], None] = &lt;function save&gt;) ‑> Iterator[bytes]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stream_artifacts(artifacts: Iterator[T], chunk_size: int, serialization_fn: Callable[[T, io.BytesIO], None] = torch.save) -&gt; Iterator[bytes]:
    eoi = False
    buff = io.BytesIO()
    while not eoi:
        while buff.tell() &lt; chunk_size:
            try:
                artifact = artifacts.__next__()
                header = buff.tell()
                buff.write(b&#34;\xde\xad\xbe\xef\xde\xad\xbe\xef&#34;)
                serialization_fn(artifact, buff)
                end = buff.tell()
                buff.seek(header)
                buff_len = (end - header - SIZE_LEN).to_bytes(SIZE_LEN,
                                                              byteorder=&#34;little&#34;)
                buff.write(buff_len)
                buff.seek(end)
            except StopIteration:
                eoi = True
                break
        position = buff.tell()
        buff.seek(0)
        if eoi:
            yield buff.read(position)
        else:
            yield buff.read(chunk_size)
            tail = buff.read(position - chunk_size)
            buff.seek(0)
            buff.write(tail)</code></pre>
</details>
</dd>
<dt id="bastionai.utils.tensor_to_bytes"><code class="name flex">
<span>def <span class="ident">tensor_to_bytes</span></span>(<span>tensor: torch.Tensor) ‑> bytes</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_to_bytes(tensor: Tensor) -&gt; bytes:
    buff = io.BytesIO()
    torch.save(tensor, buff)
    buff.seek(0)
    return buff.read()</code></pre>
</details>
</dd>
<dt id="bastionai.utils.trainable_modules"><code class="name flex">
<span>def <span class="ident">trainable_modules</span></span>(<span>module: torch.nn.modules.module.Module) ‑> Iterable[Tuple[str, torch.nn.modules.module.Module]]</span>
</code></dt>
<dd>
<div class="desc"><p>Recursively iterates over all submodules, returning those that
have parameters and are trainable (ie they want a grad).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trainable_modules(module: Module) -&gt; Iterable[Tuple[str, Module]]:
    &#34;&#34;&#34;
    Recursively iterates over all submodules, returning those that
    have parameters and are trainable (ie they want a grad).
    &#34;&#34;&#34;
    yield from (
        (m_name, m)
        for (m_name, m) in parametrized_modules(module)  # type: ignore
        if any(p.requires_grad for p in m.parameters(recurse=False))
    )</code></pre>
</details>
</dd>
<dt id="bastionai.utils.trainable_parameters"><code class="name flex">
<span>def <span class="ident">trainable_parameters</span></span>(<span>module: torch.nn.modules.module.Module) ‑> Iterable[Tuple[str, torch.nn.parameter.Parameter]]</span>
</code></dt>
<dd>
<div class="desc"><p>Recursively iterates over all parameters, returning those that
are trainable (ie they want a grad).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trainable_parameters(module: Module) -&gt; Iterable[Tuple[str, Parameter]]:
    &#34;&#34;&#34;
    Recursively iterates over all parameters, returning those that
    are trainable (ie they want a grad).
    &#34;&#34;&#34;
    yield from (
        (p_name, p) for (p_name, p) in module.named_parameters() if p.requires_grad
    )</code></pre>
</details>
</dd>
<dt id="bastionai.utils.unstream_artifacts"><code class="name flex">
<span>def <span class="ident">unstream_artifacts</span></span>(<span>stream: Iterator[bytes], deserialization_fn: Callable[[_io.BytesIO], ~T] = &lt;function load&gt;) ‑> Iterator[~T]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unstream_artifacts(stream: Iterator[bytes], deserialization_fn: Callable[[io.BytesIO], T] = torch.load) -&gt; Iterator[T]:
    buff = io.BytesIO()
    init_chunk = stream.__next__()
    size = int.from_bytes(init_chunk[:8], &#34;little&#34;)
    buff.write(init_chunk[8:])
    eoi = False

    while not eoi:
        while buff.tell() &lt; size + 4:
            try:
                buff.write(stream.__next__())
            except StopIteration:
                buff.seek(0)
                yield deserialization_fn(buff)
                eoi = True
                break

        if not eoi:
            end = buff.tell()
            buff.seek(size)
            header = buff.read(SIZE_LEN)
            size = int.from_bytes(header, &#34;little&#34;)
            tail = buff.read(end - size - SIZE_LEN)
            buff.seek(0)
            yield deserialization_fn(buff)
            buff.seek(0)
            buff.write(tail)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="bastionai.utils.ArtifactDataset"><code class="flex name class">
<span>class <span class="ident">ArtifactDataset</span></span>
<span>(</span><span>chunks: Iterator[remote_torch_pb2.Chunk])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ArtifactDataset:
    def __init__(self, chunks: Iterator[Chunk]) -&gt; None:
        wrapper = list(unstream_artifacts(
            (chunk.data for chunk in chunks),
            deserialization_fn=torch.jit.load
        ))[0]  # type: ignore
        self.samples = None
        self.labels = None
        for name, param in wrapper.named_parameters():
            if name == &#34;samples&#34;:
                self.samples = param
            elif name == &#34;labels&#34;:
                self.labels = param
            else:
                raise Exception(f&#34;Unknown field {name} in data wrapper.&#34;)
        if self.samples is None:
            raise Exception(f&#34;Data wrapper must contain a samples field.&#34;)

    def __len__(self) -&gt; int:
        return len(self.samples)

    def __getitem__(self, index: int) -&gt; Any:
        return (self.samples[index], self.labels[index])</code></pre>
</details>
</dd>
<dt id="bastionai.utils.Chunk"><code class="flex name class">
<span>class <span class="ident">Chunk</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A ProtocolMessage</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>google.protobuf.pyext._message.CMessage</li>
<li>google.protobuf.message.Message</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="bastionai.utils.Chunk.DESCRIPTOR"><code class="name">var <span class="ident">DESCRIPTOR</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="bastionai.utils.Chunk.data"><code class="name">var <span class="ident">data</span></code></dt>
<dd>
<div class="desc"><p>Field remote_torch.Chunk.data</p></div>
</dd>
<dt id="bastionai.utils.Chunk.description"><code class="name">var <span class="ident">description</span></code></dt>
<dd>
<div class="desc"><p>Field remote_torch.Chunk.description</p></div>
</dd>
<dt id="bastionai.utils.Chunk.secret"><code class="name">var <span class="ident">secret</span></code></dt>
<dd>
<div class="desc"><p>Field remote_torch.Chunk.secret</p></div>
</dd>
</dl>
</dd>
<dt id="bastionai.utils.DataWrapper"><code class="flex name class">
<span>class <span class="ident">DataWrapper</span></span>
<span>(</span><span>samples: torch.Tensor, labels: torch.Tensor)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataWrapper(Module):
    def __init__(self, samples: torch.Tensor, labels: torch.Tensor) -&gt; None:
        super().__init__()
        self.samples = Parameter(samples)
        self.labels = Parameter(labels)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="bastionai.utils.DataWrapper.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="bastionai.utils.DataWrapper.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="bastionai.utils.DataWrapper.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, *input: Any) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def _forward_unimplemented(self, *input: Any) -&gt; None:
    r&#34;&#34;&#34;Defines the computation performed at every call.

    Should be overridden by all subclasses.

    .. note::
        Although the recipe for forward pass needs to be defined within
        this function, one should call the :class:`Module` instance afterwards
        instead of this since the former takes care of running the
        registered hooks while the latter silently ignores them.
    &#34;&#34;&#34;
    raise NotImplementedError(f&#34;Module [{type(self).__name__}] is missing the required \&#34;forward\&#34; function&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="bastionai" href="index.html">bastionai</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="bastionai.utils.bytes_to_tensor" href="#bastionai.utils.bytes_to_tensor">bytes_to_tensor</a></code></li>
<li><code><a title="bastionai.utils.chunks" href="#bastionai.utils.chunks">chunks</a></code></li>
<li><code><a title="bastionai.utils.data_chunks_generator" href="#bastionai.utils.data_chunks_generator">data_chunks_generator</a></code></li>
<li><code><a title="bastionai.utils.deserialize_weights_to_model" href="#bastionai.utils.deserialize_weights_to_model">deserialize_weights_to_model</a></code></li>
<li><code><a title="bastionai.utils.make_batch" href="#bastionai.utils.make_batch">make_batch</a></code></li>
<li><code><a title="bastionai.utils.parametrized_modules" href="#bastionai.utils.parametrized_modules">parametrized_modules</a></code></li>
<li><code><a title="bastionai.utils.serialize_batch" href="#bastionai.utils.serialize_batch">serialize_batch</a></code></li>
<li><code><a title="bastionai.utils.serialize_dataset" href="#bastionai.utils.serialize_dataset">serialize_dataset</a></code></li>
<li><code><a title="bastionai.utils.serialize_model" href="#bastionai.utils.serialize_model">serialize_model</a></code></li>
<li><code><a title="bastionai.utils.stream_artifacts" href="#bastionai.utils.stream_artifacts">stream_artifacts</a></code></li>
<li><code><a title="bastionai.utils.tensor_to_bytes" href="#bastionai.utils.tensor_to_bytes">tensor_to_bytes</a></code></li>
<li><code><a title="bastionai.utils.trainable_modules" href="#bastionai.utils.trainable_modules">trainable_modules</a></code></li>
<li><code><a title="bastionai.utils.trainable_parameters" href="#bastionai.utils.trainable_parameters">trainable_parameters</a></code></li>
<li><code><a title="bastionai.utils.unstream_artifacts" href="#bastionai.utils.unstream_artifacts">unstream_artifacts</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="bastionai.utils.ArtifactDataset" href="#bastionai.utils.ArtifactDataset">ArtifactDataset</a></code></h4>
</li>
<li>
<h4><code><a title="bastionai.utils.Chunk" href="#bastionai.utils.Chunk">Chunk</a></code></h4>
<ul class="">
<li><code><a title="bastionai.utils.Chunk.DESCRIPTOR" href="#bastionai.utils.Chunk.DESCRIPTOR">DESCRIPTOR</a></code></li>
<li><code><a title="bastionai.utils.Chunk.data" href="#bastionai.utils.Chunk.data">data</a></code></li>
<li><code><a title="bastionai.utils.Chunk.description" href="#bastionai.utils.Chunk.description">description</a></code></li>
<li><code><a title="bastionai.utils.Chunk.secret" href="#bastionai.utils.Chunk.secret">secret</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="bastionai.utils.DataWrapper" href="#bastionai.utils.DataWrapper">DataWrapper</a></code></h4>
<ul class="">
<li><code><a title="bastionai.utils.DataWrapper.dump_patches" href="#bastionai.utils.DataWrapper.dump_patches">dump_patches</a></code></li>
<li><code><a title="bastionai.utils.DataWrapper.forward" href="#bastionai.utils.DataWrapper.forward">forward</a></code></li>
<li><code><a title="bastionai.utils.DataWrapper.training" href="#bastionai.utils.DataWrapper.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>